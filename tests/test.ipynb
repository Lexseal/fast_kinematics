{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinsonglin/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "# # relative import ../build/fast_kinematics\n",
    "# import sys\n",
    "# sys.path.append('../../')\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import fast_kinematics\n",
    "import pytorch_kinematics as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cu121\n"
     ]
    }
   ],
   "source": [
    "N = 4096\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fask kinematics model\n",
    "model = fast_kinematics.FastKinematics(\"../kuka_iiwa.urdf\", N, \"lbr_iiwa_link_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pk chain\n",
    "chain = pk.build_serial_chain_from_urdf(open(\"../kuka_iiwa.urdf\").read(), \"lbr_iiwa_link_7\")\n",
    "d = \"cuda\"\n",
    "dtype = torch.float32\n",
    "\n",
    "chain = chain.to(dtype=dtype, device=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for jacobian_mixed_frame: 0.009592585563659668 with std: 0.007066831660406373\n"
     ]
    }
   ],
   "source": [
    "th = torch.rand(N, 7, dtype=dtype, device=d, requires_grad=True)\n",
    "all_times = []\n",
    "J = None\n",
    "for _ in range(100):\n",
    "  start_time = time.time()\n",
    "  J = chain.jacobian(th)\n",
    "  end_time = time.time()\n",
    "  all_times.append(end_time - start_time)\n",
    "print(f\"Time taken for jacobian_mixed_frame: {np.mean(all_times)} with std: {np.std(all_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  7, 13, 19, 25, 31, 37],\n",
      "         [ 2,  8, 14, 20, 26, 32, 38],\n",
      "         [ 3,  9, 15, 21, 27, 33, 39],\n",
      "         [ 4, 10, 16, 22, 28, 34, 40],\n",
      "         [ 5, 11, 17, 23, 29, 35, 41],\n",
      "         [ 6, 12, 18, 24, 30, 36, 42]]])\n"
     ]
    }
   ],
   "source": [
    "# the output of fast_kinematics is column major 1d array, so we need to reshape it\n",
    "# experimenting to make sure we got it right\n",
    "flat_array = torch.arange(1,43)\n",
    "print(flat_array.view(-1,7,6).permute(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for fk: 4.305362701416016e-06 with std: 2.0916010452697292e-05\n"
     ]
    }
   ],
   "source": [
    "# flatten th\n",
    "th = th.view(N*7)\n",
    "all_times = []\n",
    "J2 = None\n",
    "for _ in range(1000):\n",
    "  start_time = time.time()\n",
    "  J2 = model.jacobian_mixed_frame_pytorch(th).view(-1,7,6).permute(0,2,1)\n",
    "  end_time = time.time()\n",
    "  all_times.append(end_time - start_time)\n",
    "print(f\"Time taken for fk: {np.mean(all_times)} with std: {np.std(all_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(J, J2, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for pinv: 0.03300390720367432 with std: 0.002120276819372533\n"
     ]
    }
   ],
   "source": [
    "# test out pinv vs lstsq\n",
    "\n",
    "b = torch.rand(6, 1, dtype=dtype, device=d, requires_grad=False)\n",
    "x_pinv = torch.zeros(N, 7, dtype=dtype, device=d)\n",
    "all_times = []\n",
    "for i in range(100):\n",
    "  start_time = time.time()\n",
    "  # J2 is a collection of matrices but pinv seems to work on the entire batch\n",
    "  J2_pinv = torch.pinverse(J2)\n",
    "  if i == 0: x_pinv = torch.matmul(J2_pinv, b)\n",
    "  end_time = time.time()\n",
    "  all_times.append(end_time - start_time)\n",
    "print(f\"Time taken for pinv: {np.mean(all_times)} with std: {np.std(all_times)}\")\n",
    "\n",
    "# unit test correctness of pinv for an entire batch\n",
    "first_pinv = J2[0].pinverse()\n",
    "first_x = first_pinv @ b\n",
    "assert torch.allclose(first_x, x_pinv[0], atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for lstsq: 0.024613924026489258 with std: 0.0007859006114635398\n"
     ]
    }
   ],
   "source": [
    "all_times = []\n",
    "x_lstsq = None\n",
    "new_b = b.view(1,6,1).repeat(N,1,1)  # repeat the same b for all N\n",
    "for i in range(100):\n",
    "  start_time = time.time()\n",
    "  x_lstsq = torch.linalg.lstsq(J2, new_b).solution\n",
    "  end_time = time.time()\n",
    "  all_times.append(end_time - start_time)\n",
    "print(f\"Time taken for lstsq: {np.mean(all_times)} with std: {np.std(all_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 7, 1])\n",
      "torch.Size([4096, 7, 1])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "i: 523, x: tensor([[-16880.7402],\n        [-13899.2891],\n        [ 11621.7275],\n        [-34187.2422],\n        [ 11638.2227],\n        [-11677.9277],\n        [-15916.2324]], device='cuda:0'), lstsq: tensor([[-16886.0566],\n        [-13903.6670],\n        [ 11630.2793],\n        [-34198.0156],\n        [ 11637.0029],\n        [-11681.6084],\n        [-15921.2510]], device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(J2_lstsq\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[0;32m----> 4\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(x[i], J2_lstsq[i], atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, x: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lstsq: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mJ2_lstsq[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: i: 523, x: tensor([[-16880.7402],\n        [-13899.2891],\n        [ 11621.7275],\n        [-34187.2422],\n        [ 11638.2227],\n        [-11677.9277],\n        [-15916.2324]], device='cuda:0'), lstsq: tensor([[-16886.0566],\n        [-13903.6670],\n        [ 11630.2793],\n        [-34198.0156],\n        [ 11637.0029],\n        [-11681.6084],\n        [-15921.2510]], device='cuda:0')"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(J2_lstsq.shape)\n",
    "for i in range(N):\n",
    "  assert torch.allclose(x[i], J2_lstsq[i], atol=10), f\"i: {i}, x: {x[i]}, lstsq: {J2_lstsq[i]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 6, 7])\n",
      "torch.Size([4096, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "# checking to make sure the results are the same\n",
    "print(J.shape)\n",
    "print(J2.shape)\n",
    "assert torch.allclose(J, J2, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for jacobian_mixed_frame: 0.00032803034782409666 with std: 0.0004883862096649905\n"
     ]
    }
   ],
   "source": [
    "# just for fun numpy version still faster\n",
    "qpos = np.random.rand(7*N)\n",
    "qpos = qpos.astype(np.float32)\n",
    "\n",
    "all_times = []\n",
    "for _ in range(1000):\n",
    "  start_time = time.time()\n",
    "  poses = model.jacobian_mixed_frame(qpos)\n",
    "  poses = poses.reshape(N,-1,6).transpose(0,2,1)\n",
    "  end_time = time.time()\n",
    "  all_times.append(end_time - start_time)\n",
    "print(f\"Time taken for jacobian_mixed_frame: {np.mean(all_times)} with std: {np.std(all_times)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
